{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "# Load a local model (e.g., Mistral)\n",
    "llm = Ollama(model=\"phi4:latest\", temperature=0.2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "\n",
    "# path = \"/Users/idks/.ollama/models/blobs/sha256-4824460d29f2058aaf6e1118a63a7a197a09bed509f0e7d4e2efb1ee273b447d\" # llama 3.1 70b\n",
    "# path = \"/Users/idks/.ollama/models/blobs/sha256-4cd576d9aa16961244012223abf01445567b061f1814b57dfef699e4cf8df339\" # deepseek 70b\n",
    "# path = \"/Users/idks/.ollama/models/blobs/sha256-dde5aa3fc5ffc17176b5e8bdc82f587b24b2678c6c66101bf7da77af9f7ccdff\" # llama 3.2 3b\n",
    "# path=\"/Users/idks/.ollama/models/blobs/sha256-fd7b6731c33c57f61767612f56517460ec2d1e2e5a3f0163e0eb3d8d8cb5df20\" # phi4\n",
    "path = \"/Users/idks/.ollama/models/blobs/sha256-6e9f90f02bb3b39b59e81916e8cfce9deb45aeaeb9a54a5be4414486b907dc1e\" # deepseek 14b\n",
    "\n",
    "\n",
    "llm = LlamaCPP(\n",
    "            model_path=path,\n",
    "            temperature=0.1,\n",
    "            max_new_tokens=16384,\n",
    "            context_window=16384,\n",
    "            generate_kwargs={},\n",
    "            model_kwargs={\"n_gpu_layers\": 1},  # Use GPU acceleration if available\n",
    "            verbose=True,\n",
    "            # function_calling_mode=\"schema\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd\n",
    "# from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext\n",
    "# from llama_index.core.schema import Document\n",
    "# from llama_index.core.llms import ChatMessage, MessageRole\n",
    "# from llama_index.llms.openai import OpenAI\n",
    "# from llama_index.agent.openai import OpenAIAgent\n",
    "# from llama_index.core.agent import FunctionCallingAgent\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "class CSVAgent:\n",
    "    def __init__(self, csv_path: str = None, csv_data: pd.DataFrame = None):\n",
    "        \"\"\"Initialize with either a path to a CSV file or a pandas DataFrame.\"\"\"\n",
    "        if csv_data is not None:\n",
    "            self.df = csv_data\n",
    "        elif csv_path is not None:\n",
    "            self.df = pd.read_csv(csv_path)\n",
    "        else:\n",
    "            raise ValueError(\"Either csv_path or csv_data must be provided\")\n",
    "        \n",
    "        self.csv_path = csv_path\n",
    "        self.column_info = self._get_column_info()\n",
    "        \n",
    "        self.llm = llm\n",
    "        \n",
    "        # Create tools\n",
    "        self.tools = [\n",
    "            FunctionTool.from_defaults(fn=self.get_dataframe_info),\n",
    "            FunctionTool.from_defaults(fn=self.get_column_data),\n",
    "            FunctionTool.from_defaults(fn=self.query_data),\n",
    "            FunctionTool.from_defaults(fn=self.filter_data),\n",
    "            FunctionTool.from_defaults(fn=self.group_by_data),\n",
    "            FunctionTool.from_defaults(fn=self.sort_data),\n",
    "            FunctionTool.from_defaults(fn=self.get_statistics),\n",
    "            FunctionTool.from_defaults(fn=self.generate_chart)\n",
    "        ]\n",
    "        \n",
    "        # Create agent\n",
    "        self.agent = ReActAgent.from_tools(\n",
    "            self.tools,\n",
    "            llm=self.llm,\n",
    "            verbose=True,\n",
    "            system_prompt=(\n",
    "                \"You are a helpful assistant that analyzes CSV data. \"\n",
    "                \"Use the available tools to explore, analyze, and visualize the data. \"\n",
    "                \"When using tools that return data, summarize the results in a clear and helpful way. \"\n",
    "                \"For numerical data, consider providing statistical insights. \"\n",
    "                \"For categorical data, consider providing distributions or patterns.\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def _get_column_info(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get information about the columns in the DataFrame.\"\"\"\n",
    "        info = {}\n",
    "        for col in self.df.columns:\n",
    "            info[col] = {\n",
    "                \"dtype\": str(self.df[col].dtype),\n",
    "                \"sample_values\": self.df[col].head(3).tolist(),\n",
    "                \"unique_count\": self.df[col].nunique(),\n",
    "                \"null_count\": self.df[col].isna().sum()\n",
    "            }\n",
    "        return info\n",
    "    \n",
    "    def get_dataframe_info(self) -> str:\n",
    "        \"\"\"Get basic information about the dataframe.\"\"\"\n",
    "        shape = self.df.shape\n",
    "        columns = self.df.columns.tolist()\n",
    "        dtypes = self.df.dtypes.to_dict()\n",
    "        dtypes = {k: str(v) for k, v in dtypes.items()}\n",
    "        \n",
    "        missing_data = self.df.isna().sum().to_dict()\n",
    "        \n",
    "        info = {\n",
    "            \"rows\": shape[0],\n",
    "            \"columns\": shape[1],\n",
    "            \"column_names\": columns,\n",
    "            \"dtypes\": dtypes,\n",
    "            \"missing_values\": missing_data,\n",
    "            \"sample_data\": self.df.head(5).to_dict(orient=\"records\")\n",
    "        }\n",
    "        \n",
    "        return str(info)\n",
    "    \n",
    "    def get_column_data(self, column_name: str) -> str:\n",
    "        \"\"\"Get data from a specific column.\"\"\"\n",
    "        if column_name not in self.df.columns:\n",
    "            return f\"Column '{column_name}' not found. Available columns: {', '.join(self.df.columns)}\"\n",
    "        \n",
    "        values = self.df[column_name].tolist()\n",
    "        return str(values)\n",
    "    \n",
    "    def query_data(self, query: str) -> str:\n",
    "        \"\"\"Run a pandas query on the dataframe.\"\"\"\n",
    "        try:\n",
    "            result = self.df.query(query)\n",
    "            if len(result) > 10:\n",
    "                return f\"Query returned {len(result)} rows. First 10 rows:\\n{result.head(10).to_string()}\"\n",
    "            return result.to_string()\n",
    "        except Exception as e:\n",
    "            return f\"Error executing query: {str(e)}\"\n",
    "    \n",
    "    def filter_data(self, column: str, value: str, operator: str = \"==\") -> str:\n",
    "        \"\"\"Filter dataframe based on column value.\"\"\"\n",
    "        if column not in self.df.columns:\n",
    "            return f\"Column '{column}' not found. Available columns: {', '.join(self.df.columns)}\"\n",
    "        \n",
    "        try:\n",
    "            # Convert value to appropriate type if numeric\n",
    "            if pd.api.types.is_numeric_dtype(self.df[column]):\n",
    "                try:\n",
    "                    value = float(value)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            \n",
    "            # Handle different operators\n",
    "            if operator == \"==\":\n",
    "                filtered_df = self.df[self.df[column] == value]\n",
    "            elif operator == \"!=\":\n",
    "                filtered_df = self.df[self.df[column] != value]\n",
    "            elif operator == \">\":\n",
    "                filtered_df = self.df[self.df[column] > value]\n",
    "            elif operator == \">=\":\n",
    "                filtered_df = self.df[self.df[column] >= value]\n",
    "            elif operator == \"<\":\n",
    "                filtered_df = self.df[self.df[column] < value]\n",
    "            elif operator == \"<=\":\n",
    "                filtered_df = self.df[self.df[column] <= value]\n",
    "            elif operator == \"contains\":\n",
    "                filtered_df = self.df[self.df[column].astype(str).str.contains(str(value))]\n",
    "            else:\n",
    "                return f\"Unsupported operator: {operator}\"\n",
    "            \n",
    "            if len(filtered_df) > 10:\n",
    "                return f\"Filter returned {len(filtered_df)} rows. First 10 rows:\\n{filtered_df.head(10).to_string()}\"\n",
    "            return filtered_df.to_string()\n",
    "        except Exception as e:\n",
    "            return f\"Error filtering data: {str(e)}\"\n",
    "    \n",
    "    def group_by_data(self, group_cols: str, agg_dict: str) -> str:\n",
    "        \"\"\"Group data by columns and aggregate.\"\"\"\n",
    "        try:\n",
    "            group_cols = [col.strip() for col in group_cols.split(\",\")]\n",
    "            for col in group_cols:\n",
    "                if col not in self.df.columns:\n",
    "                    return f\"Column '{col}' not found. Available columns: {', '.join(self.df.columns)}\"\n",
    "            \n",
    "            # Parse the aggregation dictionary\n",
    "            import ast\n",
    "            agg_dict = ast.literal_eval(agg_dict)\n",
    "            \n",
    "            result = self.df.groupby(group_cols).agg(agg_dict).reset_index()\n",
    "            if len(result) > 10:\n",
    "                return f\"Groupby returned {len(result)} rows. First 10 rows:\\n{result.head(10).to_string()}\"\n",
    "            return result.to_string()\n",
    "        except Exception as e:\n",
    "            return f\"Error in group by operation: {str(e)}\"\n",
    "    \n",
    "    def sort_data(self, columns: str, ascending: bool = True) -> str:\n",
    "        \"\"\"Sort dataframe by specified columns.\"\"\"\n",
    "        try:\n",
    "            sort_cols = [col.strip() for col in columns.split(\",\")]\n",
    "            for col in sort_cols:\n",
    "                if col not in self.df.columns:\n",
    "                    return f\"Column '{col}' not found. Available columns: {', '.join(self.df.columns)}\"\n",
    "            \n",
    "            result = self.df.sort_values(by=sort_cols, ascending=ascending)\n",
    "            if len(result) > 10:\n",
    "                return f\"Sorted data ({len(result)} rows). First 10 rows:\\n{result.head(10).to_string()}\"\n",
    "            return result.to_string()\n",
    "        except Exception as e:\n",
    "            return f\"Error sorting data: {str(e)}\"\n",
    "    \n",
    "    def get_statistics(self, columns: str = \"all\") -> str:\n",
    "        \"\"\"Get descriptive statistics for numeric columns.\"\"\"\n",
    "        try:\n",
    "            if columns.lower() == \"all\":\n",
    "                numeric_df = self.df.select_dtypes(include=np.number)\n",
    "                if numeric_df.empty:\n",
    "                    return \"No numeric columns found in the dataset.\"\n",
    "                return numeric_df.describe().to_string()\n",
    "            \n",
    "            columns = [col.strip() for col in columns.split(\",\")]\n",
    "            stats_df = pd.DataFrame()\n",
    "            \n",
    "            for col in columns:\n",
    "                if col not in self.df.columns:\n",
    "                    return f\"Column '{col}' not found. Available columns: {', '.join(self.df.columns)}\"\n",
    "                \n",
    "                if not pd.api.types.is_numeric_dtype(self.df[col]):\n",
    "                    return f\"Column '{col}' is not numeric. Can only get statistics for numeric columns.\"\n",
    "                \n",
    "                stats_df[col] = self.df[col]\n",
    "            \n",
    "            return stats_df.describe().to_string()\n",
    "        except Exception as e:\n",
    "            return f\"Error getting statistics: {str(e)}\"\n",
    "    \n",
    "    def generate_chart(self, chart_type: str, x_col: str, y_col: str = None, title: str = \"Chart\") -> str:\n",
    "        \"\"\"Generate a chart based on the data.\"\"\"\n",
    "        try:\n",
    "            # Validate columns\n",
    "            if x_col not in self.df.columns:\n",
    "                return f\"Column '{x_col}' not found. Available columns: {', '.join(self.df.columns)}\"\n",
    "            \n",
    "            if y_col and y_col not in self.df.columns:\n",
    "                return f\"Column '{y_col}' not found. Available columns: {', '.join(self.df.columns)}\"\n",
    "            \n",
    "            # Create different chart types\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            if chart_type.lower() == \"bar\":\n",
    "                if y_col:\n",
    "                    sns.barplot(x=self.df[x_col], y=self.df[y_col])\n",
    "                else:\n",
    "                    self.df[x_col].value_counts().plot(kind='bar')\n",
    "                \n",
    "            elif chart_type.lower() == \"histogram\":\n",
    "                sns.histplot(self.df[x_col])\n",
    "                \n",
    "            elif chart_type.lower() == \"scatter\":\n",
    "                if not y_col:\n",
    "                    return \"Scatter plot requires both x and y columns.\"\n",
    "                sns.scatterplot(x=self.df[x_col], y=self.df[y_col])\n",
    "                \n",
    "            elif chart_type.lower() == \"line\":\n",
    "                if y_col:\n",
    "                    sns.lineplot(x=self.df[x_col], y=self.df[y_col])\n",
    "                else:\n",
    "                    self.df[x_col].plot(kind='line')\n",
    "                \n",
    "            elif chart_type.lower() == \"box\":\n",
    "                sns.boxplot(x=self.df[x_col])\n",
    "                \n",
    "            elif chart_type.lower() == \"violin\":\n",
    "                if y_col:\n",
    "                    sns.violinplot(x=self.df[x_col], y=self.df[y_col])\n",
    "                else:\n",
    "                    sns.violinplot(y=self.df[x_col])\n",
    "                \n",
    "            else:\n",
    "                return f\"Chart type '{chart_type}' not supported. Supported types: bar, histogram, scatter, line, box, violin\"\n",
    "            \n",
    "            plt.title(title)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save the chart temporarily\n",
    "            temp_file = \"temp_chart.png\"\n",
    "            plt.savefig(temp_file)\n",
    "            plt.close()\n",
    "            \n",
    "            return f\"Chart generated and saved as {temp_file}\"\n",
    "        except Exception as e:\n",
    "            return f\"Error generating chart: {str(e)}\"\n",
    "    \n",
    "    def chat(self, message: str) -> str:\n",
    "        \"\"\"Chat with the agent about the CSV data.\"\"\"\n",
    "        response = self.agent.chat(message)\n",
    "        return response.response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CSVAgent(csv_path='./csv/reports.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():    \n",
    "    # Example queries\n",
    "    queries = [\n",
    "        # \"Which Channel Name has the most Total Viewership Minutes\",\n",
    "        \"Which day of the month had the highest unique viewership?\",\n",
    "        \"Which week of the month saw the most significant increase in viewership?\"\n",
    "        # \"What does this dataset contain?\",\n",
    "        # \"What's the average salary by department?\",\n",
    "        # \"Who has the highest salary?\",\n",
    "        # \"Show me a bar chart of salaries by department\",\n",
    "        # \"Is there a correlation between age and salary?\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\nQuestion: {query}\")\n",
    "        response = agent.chat(query)\n",
    "        print(f\"Answer: {response}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
